<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic | Lyuxi Liu</title>
<meta name="keywords" content="Digital Humanities, Computational Social Science, NLP, Narrative Networks, Python">
<meta name="description" content="This article provides an in-depth overview of the Narrative Network paradigm, explaining the shift from bag-of-words models to structured event triplets. It details core techniques such as Semantic Role Labeling (SRL), entity aggregation, and network backbone extraction, and includes Python code examples and empirical application analyses.">
<meta name="author" content="Lyuxi Liu">
<link rel="canonical" href="https://llspublic.github.io/posts/srl/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css" integrity="sha256-NDzEgLn/yPBMy&#43;XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://llspublic.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://llspublic.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://llspublic.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://llspublic.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://llspublic.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://llspublic.github.io/posts/srl/">
<link rel="alternate" hreflang="zh" href="https://llspublic.github.io/zh/posts/srl/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="https://llspublic.github.io/posts/srl/">
  <meta property="og:site_name" content="Lyuxi Liu">
  <meta property="og:title" content="Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic">
  <meta property="og:description" content="This article provides an in-depth overview of the Narrative Network paradigm, explaining the shift from bag-of-words models to structured event triplets. It details core techniques such as Semantic Role Labeling (SRL), entity aggregation, and network backbone extraction, and includes Python code examples and empirical application analyses.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2026-01-04T00:00:00+00:00">
    <meta property="article:modified_time" content="2026-01-04T00:00:00+00:00">
    <meta property="article:tag" content="Digital Humanities">
    <meta property="article:tag" content="Computational Social Science">
    <meta property="article:tag" content="NLP">
    <meta property="article:tag" content="Narrative Networks">
    <meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic">
<meta name="twitter:description" content="This article provides an in-depth overview of the Narrative Network paradigm, explaining the shift from bag-of-words models to structured event triplets. It details core techniques such as Semantic Role Labeling (SRL), entity aggregation, and network backbone extraction, and includes Python code examples and empirical application analyses.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://llspublic.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic",
      "item": "https://llspublic.github.io/posts/srl/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic",
  "name": "Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic",
  "description": "This article provides an in-depth overview of the Narrative Network paradigm, explaining the shift from bag-of-words models to structured event triplets. It details core techniques such as Semantic Role Labeling (SRL), entity aggregation, and network backbone extraction, and includes Python code examples and empirical application analyses.",
  "keywords": [
    "Digital Humanities", "Computational Social Science", "NLP", "Narrative Networks", "Python"
  ],
  "articleBody": " Introduction: In social science research, when faced with massive text data, we often rely on word clouds or topic models (LDA) to extract salient themes. However, these methods mainly tell us what people are talking about, while struggling to reveal the core logic of social interaction: who did what to whom.\nNarrative is not merely a linear arrangement of high-frequency words. It is a process that connects actors and patients through events, thereby constructing social reality. This article introduces a new analytical paradigm, Narrative Networks, and carefully unpacks the technical pipeline behind its implementation.\nWhy Do We Need Narrative Networks? Traditional bag-of-words models represent text as an unordered set of tokens, making it impossible to reconstruct precise relationships between roles and actions within sentences. Word frequencies or topic distributions can provide a corpus-level overview, but keywords/topics ≠ narrative. For example, LDA summarizes documents into topics that are essentially probability distributions over words, lacking explicit representations of narrative structure such as causality or role interaction.\nNarrative Networks propose a different paradigm: treating text as event sequences rather than static word sets, and emphasizing structured interactions among actors, actions, and patients. In other words, narrative networks focus on who (agent), to whom (patient), and did what (action), capturing causal contours and responsibility attribution in discourse. This shift allows researchers to move beyond topical discussion and examine how discourse shapes social cognition and power structures.\nParadigm Comparison: Co-word Networks vs. Narrative Networks Analytical Dimension Co-word Network Narrative Network Basic Unit word A – word B (co-occurrence) agent – action – patient (event triplet) Link Basis statistical association (frequency/co-occurrence) semantic interaction (role relations) Graph Type undirected directed Interpretability topical relatedness (what is discussed) action logic (who did what to whom) By preserving event structure, narrative networks greatly enhance interpretability for how social reality is constructed. For instance, Sudhahar et al. built networks from subject–verb–object relations in news reports and identified two emergent camps (support vs. opposition) in U.S. election corpora. Compared with co-occurrence analysis, narrative networks better uncover power relations and causal chains, making them a strong tool for political communication, public opinion analysis, and related domains.\nPart I: Theoretical Lens — From Topic Mining to Narrative Parsing Text analysis is undergoing a paradigm shift from identifying explicit topics (e.g., high-frequency words, latent topics) to parsing implicit narrative structures (e.g., role interactions, event logic). Several theoretical motivations underlie this shift:\nHumans are “storytelling animals”. Narrative is a fundamental way humans understand and organize reality. Online narrative dynamics such as emergence, competition, and decay can have profound real-world consequences. Understanding narrative structures in online discourse helps interpret public opinion trajectories and influence. Overcoming the limits of bag-of-words. BoW ignores word order and syntax, collapsing crucial distinctions such as “dog bites man” versus “man bites dog.” Narrative analysis instead centers predicates and argument roles to precisely capture who did what. Explaining social interaction. Narrative networks translate text into actor–event graphs, enabling researchers to examine interaction patterns at scale. Centrality measures can identify core actors in a discourse arena, while community detection reveals narrative communities around specific issues. Robert Allen and others have argued that converting a plot’s temporal flow into a “two-dimensional network map” makes structure immediately visible. Applying network methods to narrative thus enables macro-level capture of symmetry and structural features in discourse, allowing quantification of power relations among roles.\nPart II: Core Technique — Semantic Role Labeling (SRL) Semantic Role Labeling (SRL) is the foundation of narrative network construction. SRL parses predicates, typically verbs, and identifies the semantic roles of their participants (arguments), extracting who, when, where, did what, to whom. Conceptually, it is akin to automatically annotating a sentence with a screenplay-style cast list.\nPredicate: usually the main verb, indicating an action or event. Arguments: participants and elements related to that action, each assigned a specific semantic role. PropBank-Style Roles ARG0: Agent, the initiator of the action. In “The government introduced a new policy,” the government is ARG0. ARG1: Patient or theme, the entity affected by the action. In the same example, a new policy is ARG1. ARGM: Modifiers, including time (TMP), location (LOC), manner (MNR), and others. Through SRL, unstructured language becomes structured event descriptions. For example, the sentence “The CDC confirms the first coronavirus case.” can be parsed as:\n[ARG0: The CDC] [V: confirms] [ARG1: the first coronavirus case]\nSRL Tools and Models Early SRL systems such as SENNA could annotate basic roles. In recent years, pretrained language models like BERT have substantially improved SRL accuracy. AllenNLP provides an out-of-the-box BERT-based SRL predictor that can be used without training from scratch:\nfrom allennlp.predictors import Predictor # Load a pretrained BERT-SRL model (local path or URL) predictor = Predictor.from_path( \"https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz\" ) # Input sentence sentence = \"The CDC confirms the first coronavirus case.\" result = predictor.predict(sentence=sentence) # Print SRL outputs for verb in result['verbs']: print(verb['description']) # Expected output: # [ARG0: The CDC] [V: confirms] [ARG1: the first coronavirus case]. Part III: Narrative Aggregation — From Micro Events to Macro Networks After SRL parsing, we obtain a large collection of micro-level narrative fragments (event triplets). These raw triplets are often sparse and noisy due to the variability of natural language. To extract robust collective narratives, aggregation and normalization are required so that similar actors and synonymous actions are merged into unified nodes and relations.\n1. Verb Normalization Different surface forms of semantically similar verbs are mapped into shared action frames. For example, “support,” “endorse,” and “back” can be normalized into a general support-type action. Lexical resources such as VerbAtlas facilitate this process by mapping thousands of verb senses into a few hundred generalized predicate frames.\n2. Argument Clustering Different surface forms may refer to the same entity, such as “United States,” “USA,” and “U.S.” A common solution is semantic embeddings plus clustering. Sentence-BERT encodes each argument phrase, and agglomerative (hierarchical) clustering groups semantically similar mentions.\nfrom sentence_transformers import SentenceTransformer from sklearn.cluster import AgglomerativeClustering entities = [\"United States\", \"USA\", \"U.S.\", \"every Asian person\", \"Asian people\"] embedder = SentenceTransformer('all-MiniLM-L6-v2') embeddings = embedder.encode(entities) clustering = AgglomerativeClustering( n_clusters=None, distance_threshold=0.4, affinity='cosine', linkage='average' ) labels = clustering.fit_predict(embeddings) for entity, label in zip(entities, labels): print(f\"{entity} -\u003e Cluster {label}\") These steps perform semantic compression, yielding a more compact and standardized set of narrative events.\nPart IV: Network Construction and Visual Analytics With normalized verbs and entities, events can be organized into a narrative network for quantitative analysis and visualization.\n1. Defining a Narrative Network A narrative network is a directed weighted graph.\nNodes represent actors or actants. Edges represent narrative relations, directed from ARG0 to ARG1 and labeled with predicate frames. Weights capture relation strength, often via frequency or statistical measures such as log-odds ratios. 2. Backbone Extraction and Denoising Narrative networks derived from real corpora are often dense. Multiscale backbone extraction filters statistically insignificant edges, highlighting dominant narrative pathways.\nimport networkx as nx G = nx.DiGraph() for (subj, verb, obj) in aggregated_triplets: if G.has_edge(subj, obj): G[subj][obj]['weight'] += 1 else: G.add_edge(subj, obj, label=verb, weight=1) avg_weight = sum(d['weight'] for _, _, d in G.edges(data=True)) / G.number_of_edges() backbone_edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['weight'] \u003e= avg_weight] G_core = nx.DiGraph() G_core.add_edges_from(backbone_edges) print(\"Original edges:\", G.number_of_edges()) print(\"Backbone edges:\", G_core.number_of_edges()) 3. Visualization and Interaction Interactive libraries such as PyVis or D3.js enable zooming and inspection. Physics-based layouts reveal community structure, while visual encodings convey centrality, role type, or action category.\nPart V: Empirical Applications and Findings Narrative networks have demonstrated strong analytical value in empirical studies. Zhao et al. applied this framework to the 2017 French presidential election and COVID-19 Twitter corpora, reporting findings including:\nRole images and narrative polarization. Le Pen was associated with negatively framed actions, while Macron was linked to neutral or campaign-related actions. Event-driven narrative shifts. Turning points in narrative structure aligned closely with major real-world events such as debates or scandals. Structural properties. Network topology exhibited clear core–periphery patterns, with a small set of high-centrality actors dominating discourse. Part VI: Frontier Directions and Challenges Narrative network analysis continues to evolve.\n1. Cross-Modal Narrative Parsing Narratives extend beyond text.\nVisual SRL extracts event structures from images. Video SRL segments videos into event chains, producing cross-modal narrative graphs. 2. Technical Challenges Metaphor and irony remain difficult for current SRL models. Cross-sentence narrative chains require linking events beyond single sentences. Generative approaches with LLMs may enable direct generation of structured narrative graphs from full documents. Conclusion: Narrative network analysis advances text mining from word frequency to action logic. By extracting “who did what to whom” at scale, SRL-driven pipelines enable quantifiable and visualizable representations of collective narratives.\nReferences SOURCE: IC2S2 OSoMe Tutorial 2024 AUTHOR: @汤圆键盘坏了不能写论文（Xiaohongshu） [1] Zhao, W. et al. (2024). Discovering Collective Narratives Shifts in Online Discussions. ICWSM 2024. [2] Willaert, T. et al. (2023). Extracting narrative signals from public discourse: a network-based approach. Humanit. Soc. Sci. Commun. [3] Serrano, M. Á. et al. (2009). Extracting the multiscale backbone of complex weighted networks. PNAS. [4] Reimers, N., Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP 2019. [5] Yatskar, M. et al. (2016). Situation Recognition: Visual Semantic Role Labeling for Image Understanding. CVPR 2016. [6] OSoMe Tutorial 2024 / IC2S2 Tutorial on Narrative Networks. ",
  "wordCount" : "1517",
  "inLanguage": "en",
  "datePublished": "2026-01-04T00:00:00Z",
  "dateModified": "2026-01-04T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lyuxi Liu"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://llspublic.github.io/posts/srl/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lyuxi Liu",
    "logo": {
      "@type": "ImageObject",
      "url": "https://llspublic.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://llspublic.github.io/" accesskey="h" title="Lyuxi Liu (Alt + H)">Lyuxi Liu</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                    <ul class="lang-switch"><li>|</li>
                        <li>
                            <a href="https://llspublic.github.io/zh/" title="中文"
                                aria-label="中文">Zh</a>
                        </li>
                    </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://llspublic.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://llspublic.github.io/archive/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Deep Dive into Narrative Networks: From Bag-of-Words to Structured Action Logic
    </h1>
    <div class="post-meta"><span title='2026-01-04 00:00:00 +0000 UTC'>January 4, 2026</span>&nbsp;·&nbsp;<span>Lyuxi Liu</span>&nbsp;|&nbsp;<span>Translations:</span>
<ul class="i18n_list">
    <li>
        <a href="https://llspublic.github.io/zh/posts/srl/">Zh</a>
    </li>
</ul>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#why-do-we-need-narrative-networks" aria-label="Why Do We Need Narrative Networks?">Why Do We Need Narrative Networks?</a><ul>
                        
                <li>
                    <a href="#paradigm-comparison-co-word-networks-vs-narrative-networks" aria-label="Paradigm Comparison: Co-word Networks vs. Narrative Networks">Paradigm Comparison: Co-word Networks vs. Narrative Networks</a></li></ul>
                </li>
                <li>
                    <a href="#part-i-theoretical-lens--from-topic-mining-to-narrative-parsing" aria-label="Part I: Theoretical Lens — From Topic Mining to Narrative Parsing">Part I: Theoretical Lens — From Topic Mining to Narrative Parsing</a></li>
                <li>
                    <a href="#part-ii-core-technique--semantic-role-labeling-srl" aria-label="Part II: Core Technique — Semantic Role Labeling (SRL)">Part II: Core Technique — Semantic Role Labeling (SRL)</a><ul>
                        
                <li>
                    <a href="#propbank-style-roles" aria-label="PropBank-Style Roles">PropBank-Style Roles</a></li>
                <li>
                    <a href="#srl-tools-and-models" aria-label="SRL Tools and Models">SRL Tools and Models</a></li></ul>
                </li>
                <li>
                    <a href="#part-iii-narrative-aggregation--from-micro-events-to-macro-networks" aria-label="Part III: Narrative Aggregation — From Micro Events to Macro Networks">Part III: Narrative Aggregation — From Micro Events to Macro Networks</a><ul>
                        
                <li>
                    <a href="#1-verb-normalization" aria-label="1. Verb Normalization">1. Verb Normalization</a></li>
                <li>
                    <a href="#2-argument-clustering" aria-label="2. Argument Clustering">2. Argument Clustering</a></li></ul>
                </li>
                <li>
                    <a href="#part-iv-network-construction-and-visual-analytics" aria-label="Part IV: Network Construction and Visual Analytics">Part IV: Network Construction and Visual Analytics</a><ul>
                        
                <li>
                    <a href="#1-defining-a-narrative-network" aria-label="1. Defining a Narrative Network">1. Defining a Narrative Network</a></li>
                <li>
                    <a href="#2-backbone-extraction-and-denoising" aria-label="2. Backbone Extraction and Denoising">2. Backbone Extraction and Denoising</a></li>
                <li>
                    <a href="#3-visualization-and-interaction" aria-label="3. Visualization and Interaction">3. Visualization and Interaction</a></li></ul>
                </li>
                <li>
                    <a href="#part-v-empirical-applications-and-findings" aria-label="Part V: Empirical Applications and Findings">Part V: Empirical Applications and Findings</a></li>
                <li>
                    <a href="#part-vi-frontier-directions-and-challenges" aria-label="Part VI: Frontier Directions and Challenges">Part VI: Frontier Directions and Challenges</a><ul>
                        
                <li>
                    <a href="#1-cross-modal-narrative-parsing" aria-label="1. Cross-Modal Narrative Parsing">1. Cross-Modal Narrative Parsing</a></li>
                <li>
                    <a href="#2-technical-challenges" aria-label="2. Technical Challenges">2. Technical Challenges</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><hr>
<blockquote>
<p><strong>Introduction</strong>: In social science research, when faced with massive text data, we often rely on word clouds or topic models (LDA) to extract salient themes. However, these methods mainly tell us <strong>what</strong> people are talking about, while struggling to reveal the core logic of social interaction: <strong>who did what to whom</strong>.</p>
</blockquote>
<p>Narrative is not merely a linear arrangement of high-frequency words. It is a process that connects actors and patients through events, thereby constructing social reality. This article introduces a new analytical paradigm, <strong>Narrative Networks</strong>, and carefully unpacks the technical pipeline behind its implementation.</p>
<h2 id="why-do-we-need-narrative-networks">Why Do We Need Narrative Networks?<a hidden class="anchor" aria-hidden="true" href="#why-do-we-need-narrative-networks">#</a></h2>
<p>Traditional bag-of-words models represent text as an unordered set of tokens, making it impossible to reconstruct precise relationships between roles and actions within sentences. Word frequencies or topic distributions can provide a corpus-level overview, but <strong>keywords/topics ≠ narrative</strong>. For example, LDA summarizes documents into topics that are essentially probability distributions over words, lacking explicit representations of narrative structure such as causality or role interaction.</p>
<p><strong>Narrative Networks</strong> propose a different paradigm: treating text as <strong>event sequences</strong> rather than static word sets, and emphasizing <strong>structured interactions</strong> among actors, actions, and patients. In other words, narrative networks focus on <strong>who</strong> (agent), <strong>to whom</strong> (patient), and <strong>did what</strong> (action), capturing causal contours and responsibility attribution in discourse. This shift allows researchers to move beyond topical discussion and examine how discourse shapes social cognition and power structures.</p>
<h3 id="paradigm-comparison-co-word-networks-vs-narrative-networks">Paradigm Comparison: Co-word Networks vs. Narrative Networks<a hidden class="anchor" aria-hidden="true" href="#paradigm-comparison-co-word-networks-vs-narrative-networks">#</a></h3>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Analytical Dimension</th>
          <th style="text-align: left">Co-word Network</th>
          <th style="text-align: left">Narrative Network</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Basic Unit</strong></td>
          <td style="text-align: left">word A – word B (co-occurrence)</td>
          <td style="text-align: left">agent – action – patient (event triplet)</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Link Basis</strong></td>
          <td style="text-align: left">statistical association (frequency/co-occurrence)</td>
          <td style="text-align: left">semantic interaction (role relations)</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Graph Type</strong></td>
          <td style="text-align: left">undirected</td>
          <td style="text-align: left">directed</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Interpretability</strong></td>
          <td style="text-align: left">topical relatedness (what is discussed)</td>
          <td style="text-align: left">action logic (who did what to whom)</td>
      </tr>
  </tbody>
</table>
<p>By preserving event structure, narrative networks greatly enhance interpretability for how social reality is constructed. For instance, Sudhahar et al. built networks from subject–verb–object relations in news reports and identified two emergent camps (support vs. opposition) in U.S. election corpora. Compared with co-occurrence analysis, narrative networks better uncover power relations and causal chains, making them a strong tool for political communication, public opinion analysis, and related domains.</p>
<hr>
<h2 id="part-i-theoretical-lens--from-topic-mining-to-narrative-parsing">Part I: Theoretical Lens — From Topic Mining to Narrative Parsing<a hidden class="anchor" aria-hidden="true" href="#part-i-theoretical-lens--from-topic-mining-to-narrative-parsing">#</a></h2>
<p>Text analysis is undergoing a paradigm shift from identifying <strong>explicit topics</strong> (e.g., high-frequency words, latent topics) to parsing <strong>implicit narrative structures</strong> (e.g., role interactions, event logic). Several theoretical motivations underlie this shift:</p>
<ol>
<li><strong>Humans are “storytelling animals”</strong>. Narrative is a fundamental way humans understand and organize reality. Online narrative dynamics such as emergence, competition, and decay can have profound real-world consequences. Understanding narrative structures in online discourse helps interpret public opinion trajectories and influence.</li>
<li><strong>Overcoming the limits of bag-of-words</strong>. BoW ignores word order and syntax, collapsing crucial distinctions such as “dog bites man” versus “man bites dog.” Narrative analysis instead centers predicates and argument roles to precisely capture who did what.</li>
<li><strong>Explaining social interaction</strong>. Narrative networks translate text into actor–event graphs, enabling researchers to examine interaction patterns at scale. Centrality measures can identify core actors in a discourse arena, while community detection reveals narrative communities around specific issues.</li>
</ol>
<p>Robert Allen and others have argued that converting a plot’s temporal flow into a “two-dimensional network map” makes structure immediately visible. Applying network methods to narrative thus enables macro-level capture of <strong>symmetry</strong> and <strong>structural features</strong> in discourse, allowing quantification of power relations among roles.</p>
<hr>
<h2 id="part-ii-core-technique--semantic-role-labeling-srl">Part II: Core Technique — Semantic Role Labeling (SRL)<a hidden class="anchor" aria-hidden="true" href="#part-ii-core-technique--semantic-role-labeling-srl">#</a></h2>
<p><strong>Semantic Role Labeling (SRL)</strong> is the foundation of narrative network construction. SRL parses predicates, typically verbs, and identifies the semantic roles of their participants (arguments), extracting <strong>who, when, where, did what, to whom</strong>. Conceptually, it is akin to automatically annotating a sentence with a screenplay-style cast list.</p>
<ul>
<li><strong>Predicate</strong>: usually the main verb, indicating an action or event.</li>
<li><strong>Arguments</strong>: participants and elements related to that action, each assigned a specific semantic role.</li>
</ul>
<h3 id="propbank-style-roles">PropBank-Style Roles<a hidden class="anchor" aria-hidden="true" href="#propbank-style-roles">#</a></h3>
<ul>
<li><strong>ARG0</strong>: Agent, the initiator of the action. In “The government introduced a new policy,” <strong>the government</strong> is ARG0.</li>
<li><strong>ARG1</strong>: Patient or theme, the entity affected by the action. In the same example, <strong>a new policy</strong> is ARG1.</li>
<li><strong>ARGM</strong>: Modifiers, including time (TMP), location (LOC), manner (MNR), and others.</li>
</ul>
<p>Through SRL, unstructured language becomes structured event descriptions. For example, the sentence <em>“The CDC confirms the first coronavirus case.”</em> can be parsed as:</p>
<blockquote>
<p><strong>[ARG0: The CDC] [V: confirms] [ARG1: the first coronavirus case]</strong></p>
</blockquote>
<h3 id="srl-tools-and-models">SRL Tools and Models<a hidden class="anchor" aria-hidden="true" href="#srl-tools-and-models">#</a></h3>
<p>Early SRL systems such as SENNA could annotate basic roles. In recent years, pretrained language models like BERT have substantially improved SRL accuracy. <strong>AllenNLP</strong> provides an out-of-the-box BERT-based SRL predictor that can be used without training from scratch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.predictors <span style="color:#f92672">import</span> Predictor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load a pretrained BERT-SRL model (local path or URL)</span>
</span></span><span style="display:flex;"><span>predictor <span style="color:#f92672">=</span> Predictor<span style="color:#f92672">.</span>from_path(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Input sentence</span>
</span></span><span style="display:flex;"><span>sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;The CDC confirms the first coronavirus case.&#34;</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> predictor<span style="color:#f92672">.</span>predict(sentence<span style="color:#f92672">=</span>sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print SRL outputs</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> verb <span style="color:#f92672">in</span> result[<span style="color:#e6db74">&#39;verbs&#39;</span>]:
</span></span><span style="display:flex;"><span>    print(verb[<span style="color:#e6db74">&#39;description&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Expected output:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [ARG0: The CDC] [V: confirms] [ARG1: the first coronavirus case].</span>
</span></span></code></pre></div><hr>
<h2 id="part-iii-narrative-aggregation--from-micro-events-to-macro-networks">Part III: Narrative Aggregation — From Micro Events to Macro Networks<a hidden class="anchor" aria-hidden="true" href="#part-iii-narrative-aggregation--from-micro-events-to-macro-networks">#</a></h2>
<p>After SRL parsing, we obtain a large collection of <strong>micro-level narrative fragments</strong> (event triplets). These raw triplets are often sparse and noisy due to the variability of natural language. To extract robust <strong>collective narratives</strong>, aggregation and normalization are required so that <strong>similar actors</strong> and <strong>synonymous actions</strong> are merged into unified nodes and relations.</p>
<h3 id="1-verb-normalization">1. Verb Normalization<a hidden class="anchor" aria-hidden="true" href="#1-verb-normalization">#</a></h3>
<p>Different surface forms of semantically similar verbs are mapped into shared action frames. For example, “support,” “endorse,” and “back” can be normalized into a general support-type action. Lexical resources such as <strong>VerbAtlas</strong> facilitate this process by mapping thousands of verb senses into a few hundred generalized predicate frames.</p>
<h3 id="2-argument-clustering">2. Argument Clustering<a hidden class="anchor" aria-hidden="true" href="#2-argument-clustering">#</a></h3>
<p>Different surface forms may refer to the same entity, such as “United States,” “USA,” and “U.S.” A common solution is <strong>semantic embeddings plus clustering</strong>. <strong>Sentence-BERT</strong> encodes each argument phrase, and <strong>agglomerative (hierarchical) clustering</strong> groups semantically similar mentions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> SentenceTransformer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cluster <span style="color:#f92672">import</span> AgglomerativeClustering
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>entities <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;United States&#34;</span>, <span style="color:#e6db74">&#34;USA&#34;</span>, <span style="color:#e6db74">&#34;U.S.&#34;</span>, <span style="color:#e6db74">&#34;every Asian person&#34;</span>, <span style="color:#e6db74">&#34;Asian people&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>embedder <span style="color:#f92672">=</span> SentenceTransformer(<span style="color:#e6db74">&#39;all-MiniLM-L6-v2&#39;</span>)
</span></span><span style="display:flex;"><span>embeddings <span style="color:#f92672">=</span> embedder<span style="color:#f92672">.</span>encode(entities)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>clustering <span style="color:#f92672">=</span> AgglomerativeClustering(
</span></span><span style="display:flex;"><span>    n_clusters<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    distance_threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>,
</span></span><span style="display:flex;"><span>    affinity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cosine&#39;</span>,
</span></span><span style="display:flex;"><span>    linkage<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;average&#39;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>labels <span style="color:#f92672">=</span> clustering<span style="color:#f92672">.</span>fit_predict(embeddings)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> entity, label <span style="color:#f92672">in</span> zip(entities, labels):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>entity<span style="color:#e6db74">}</span><span style="color:#e6db74"> -&gt; Cluster </span><span style="color:#e6db74">{</span>label<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>These steps perform <strong>semantic compression</strong>, yielding a more <strong>compact and standardized</strong> set of narrative events.</p>
<hr>
<h2 id="part-iv-network-construction-and-visual-analytics">Part IV: Network Construction and Visual Analytics<a hidden class="anchor" aria-hidden="true" href="#part-iv-network-construction-and-visual-analytics">#</a></h2>
<p>With normalized verbs and entities, events can be organized into a <strong>narrative network</strong> for quantitative analysis and visualization.</p>
<h3 id="1-defining-a-narrative-network">1. Defining a Narrative Network<a hidden class="anchor" aria-hidden="true" href="#1-defining-a-narrative-network">#</a></h3>
<p>A narrative network is a <strong>directed weighted graph</strong>.</p>
<ul>
<li><strong>Nodes</strong> represent actors or actants.</li>
<li><strong>Edges</strong> represent narrative relations, directed from ARG0 to ARG1 and labeled with predicate frames.</li>
<li><strong>Weights</strong> capture relation strength, often via frequency or statistical measures such as log-odds ratios.</li>
</ul>
<h3 id="2-backbone-extraction-and-denoising">2. Backbone Extraction and Denoising<a hidden class="anchor" aria-hidden="true" href="#2-backbone-extraction-and-denoising">#</a></h3>
<p>Narrative networks derived from real corpora are often dense. <strong>Multiscale backbone extraction</strong> filters statistically insignificant edges, highlighting dominant narrative pathways.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> networkx <span style="color:#66d9ef">as</span> nx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>G <span style="color:#f92672">=</span> nx<span style="color:#f92672">.</span>DiGraph()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (subj, verb, obj) <span style="color:#f92672">in</span> aggregated_triplets:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> G<span style="color:#f92672">.</span>has_edge(subj, obj):
</span></span><span style="display:flex;"><span>        G[subj][obj][<span style="color:#e6db74">&#39;weight&#39;</span>] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        G<span style="color:#f92672">.</span>add_edge(subj, obj, label<span style="color:#f92672">=</span>verb, weight<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>avg_weight <span style="color:#f92672">=</span> sum(d[<span style="color:#e6db74">&#39;weight&#39;</span>] <span style="color:#66d9ef">for</span> _, _, d <span style="color:#f92672">in</span> G<span style="color:#f92672">.</span>edges(data<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)) <span style="color:#f92672">/</span> G<span style="color:#f92672">.</span>number_of_edges()
</span></span><span style="display:flex;"><span>backbone_edges <span style="color:#f92672">=</span> [(u, v, d) <span style="color:#66d9ef">for</span> u, v, d <span style="color:#f92672">in</span> G<span style="color:#f92672">.</span>edges(data<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#66d9ef">if</span> d[<span style="color:#e6db74">&#39;weight&#39;</span>] <span style="color:#f92672">&gt;=</span> avg_weight]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>G_core <span style="color:#f92672">=</span> nx<span style="color:#f92672">.</span>DiGraph()
</span></span><span style="display:flex;"><span>G_core<span style="color:#f92672">.</span>add_edges_from(backbone_edges)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Original edges:&#34;</span>, G<span style="color:#f92672">.</span>number_of_edges())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Backbone edges:&#34;</span>, G_core<span style="color:#f92672">.</span>number_of_edges())
</span></span></code></pre></div><h3 id="3-visualization-and-interaction">3. Visualization and Interaction<a hidden class="anchor" aria-hidden="true" href="#3-visualization-and-interaction">#</a></h3>
<p>Interactive libraries such as PyVis or D3.js enable zooming and inspection. Physics-based layouts reveal <strong>community structure</strong>, while visual encodings convey centrality, role type, or action category.</p>
<hr>
<h2 id="part-v-empirical-applications-and-findings">Part V: Empirical Applications and Findings<a hidden class="anchor" aria-hidden="true" href="#part-v-empirical-applications-and-findings">#</a></h2>
<p>Narrative networks have demonstrated strong analytical value in empirical studies. Zhao et al. applied this framework to the <strong>2017 French presidential election</strong> and <strong>COVID-19 Twitter corpora</strong>, reporting findings including:</p>
<ol>
<li><strong>Role images and narrative polarization</strong>. Le Pen was associated with negatively framed actions, while Macron was linked to neutral or campaign-related actions.</li>
<li><strong>Event-driven narrative shifts</strong>. Turning points in narrative structure aligned closely with major real-world events such as debates or scandals.</li>
<li><strong>Structural properties</strong>. Network topology exhibited clear <strong>core–periphery</strong> patterns, with a small set of high-centrality actors dominating discourse.</li>
</ol>
<hr>
<h2 id="part-vi-frontier-directions-and-challenges">Part VI: Frontier Directions and Challenges<a hidden class="anchor" aria-hidden="true" href="#part-vi-frontier-directions-and-challenges">#</a></h2>
<p>Narrative network analysis continues to evolve.</p>
<h3 id="1-cross-modal-narrative-parsing">1. Cross-Modal Narrative Parsing<a hidden class="anchor" aria-hidden="true" href="#1-cross-modal-narrative-parsing">#</a></h3>
<p>Narratives extend beyond text.</p>
<ul>
<li><strong>Visual SRL</strong> extracts event structures from images.</li>
<li><strong>Video SRL</strong> segments videos into event chains, producing cross-modal narrative graphs.</li>
</ul>
<h3 id="2-technical-challenges">2. Technical Challenges<a hidden class="anchor" aria-hidden="true" href="#2-technical-challenges">#</a></h3>
<ul>
<li><strong>Metaphor and irony</strong> remain difficult for current SRL models.</li>
<li><strong>Cross-sentence narrative chains</strong> require linking events beyond single sentences.</li>
<li><strong>Generative approaches with LLMs</strong> may enable direct generation of structured narrative graphs from full documents.</li>
</ul>
<hr>
<p><strong>Conclusion</strong>: Narrative network analysis advances text mining from word frequency to action logic. By extracting “who did what to whom” at scale, SRL-driven pipelines enable quantifiable and visualizable representations of collective narratives.</p>
<h3 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h3>
<ul>
<li>SOURCE: IC2S2 OSoMe Tutorial 2024</li>
<li>AUTHOR: @汤圆键盘坏了不能写论文（Xiaohongshu）</li>
<li>[1] Zhao, W. et al. (2024). <em>Discovering Collective Narratives Shifts in Online Discussions</em>. ICWSM 2024.</li>
<li>[2] Willaert, T. et al. (2023). <em>Extracting narrative signals from public discourse: a network-based approach</em>. Humanit. Soc. Sci. Commun.</li>
<li>[3] Serrano, M. Á. et al. (2009). <em>Extracting the multiscale backbone of complex weighted networks</em>. PNAS.</li>
<li>[4] Reimers, N., Gurevych, I. (2019). <em>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</em>. EMNLP 2019.</li>
<li>[5] Yatskar, M. et al. (2016). <em>Situation Recognition: Visual Semantic Role Labeling for Image Understanding</em>. CVPR 2016.</li>
<li>[6] OSoMe Tutorial 2024 / IC2S2 Tutorial on Narrative Networks.</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://llspublic.github.io/tags/digital-humanities/">Digital Humanities</a></li>
      <li><a href="https://llspublic.github.io/tags/computational-social-science/">Computational Social Science</a></li>
      <li><a href="https://llspublic.github.io/tags/nlp/">NLP</a></li>
      <li><a href="https://llspublic.github.io/tags/narrative-networks/">Narrative Networks</a></li>
      <li><a href="https://llspublic.github.io/tags/python/">Python</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://llspublic.github.io/">Lyuxi Liu</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
